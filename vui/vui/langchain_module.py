# langchain_module.py

import os
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

from util import config, exceptions

class LangChainModule:
    def __init__(self):
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "../resource/.env"))
        self.api_key = os.getenv("OPENAI_API_KEY")

        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.5,
            openai_api_key=self.api_key
        )

        prompt_template = config.prompt_template

        self.chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(input_variables=[config.user_input], template=prompt_template)
        )

    def extract(self, user_input: str):
        """í…ìŠ¤íŠ¸ ëª…ë ¹ì–´ì—ì„œ íƒ€ê²Ÿë³„ task_step ì‹œí€€ìŠ¤ ì¶”ì¶œ"""
        response = self.chain.invoke({config.user_input: user_input})
        raw_result = response["text"]
        # print(f"ğŸ§  LLM ì‘ë‹µ: {raw_result}")

        # print(f"ê²°ê³¼ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.")
        try:
            parts = [p.strip() for p in raw_result.strip().split("/")]
            targets = parts[0].split() if parts[0] else []
            steps_per_target = [p.strip().split() for p in parts[1:]] if len(parts) > 1 else []
        except Exception:
            raise exceptions.VUI_ERROR(401)

        # print(f"ğŸ”§ ì¶”ì¶œëœ ë„êµ¬: {targets}")
        # print(f"ğŸ“ íƒ€ê²Ÿë³„ ëª©ì ì§€: {steps_per_target}")
        return targets, steps_per_target


#############################
# âœ… ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš©
#############################
if __name__ == "__main__":
    lc = LangChainModule()
    test_sentence = input("ğŸ—£ï¸ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    lc.extract(test_sentence)
