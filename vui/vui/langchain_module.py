# langchain_module.py

import os
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

from util import config, exceptions

class LangChainModule:
    def __init__(self):
        load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "../resource/.env"))
        self.api_key = os.getenv("OPENAI_API_KEY")

        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.5,
            openai_api_key=self.api_key
        )

        prompt_template = config.prompt_template

        self.chain = LLMChain(
            llm=self.llm,
            prompt=PromptTemplate(input_variables=[config.user_input], template=prompt_template)
        )

    def extract(self, user_input: str):
        """í…ìŠ¤íŠ¸ ëª…ë ¹ì–´ì—ì„œ ë„êµ¬/ëª©ì ì§€ ì¶”ì¶œ"""
        response = self.chain.invoke({config.user_input: user_input})
        raw_result = response["text"]
        print(f"[{__name__}] ğŸ§  LLM ì‘ë‹µ: {raw_result}")

        # ê²°ê³¼ íŒŒì‹±
        try:
            targets_raw, task_steps_raw = raw_result.strip().split("/")
            targets = targets_raw.strip().split()
            task_steps = task_steps_raw.strip().split()
        except Exception:
            raise exceptions.VUI_ERROR(401)

        print(f"[{__name__}] ğŸ”§ ì¶”ì¶œëœ ë„êµ¬: {targets}")
        print(f"[{__name__}] ğŸ“ ì¶”ì¶œëœ ëª©ì ì§€: {task_steps}")
        return targets, task_steps


#############################
# âœ… ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš©
#############################
if __name__ == "__main__":
    lc = LangChainModule()
    test_sentence = input("ğŸ—£ï¸ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    lc.extract(test_sentence)
